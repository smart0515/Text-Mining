{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4b5eac16",
   "metadata": {},
   "source": [
    "HuggingFace transformers와 Tensorflow를 통해 사전학습모델을 Fine-tuning하는 <br> 방법 및 학습된 모델을 통해 **Multi-class text classfication** 문제를 해결해보자"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f59d190e",
   "metadata": {},
   "source": [
    "# Load Dataset\n",
    "**Load Trainset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f808e51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T02:32:09.401588Z",
     "start_time": "2023-06-06T02:32:09.050259Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cf890ba6",
   "metadata": {},
   "source": [
    "- 데이터 셋의 경우 KLUE에서 Topic-Classification을 위해 사용한 YNAT 데이터 셋을 그대로 사용하였다.<br>\n",
    "- YNAT는 연합뉴스의 2016-202년까지의 뉴스 headline을 수집한 데이터 셋이며, 총 7가지 클래스(IT과학, 경제, 사회, 생활문화, 세계, 스포츠, 정치)로 분류되어있다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "48a9dac3",
   "metadata": {},
   "source": [
    "**Dataset : https://github.com/KLUE-benchmark/KLUE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d3af21e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T02:32:09.873664Z",
     "start_time": "2023-06-06T02:32:09.402588Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>유튜브 내달 2일까지 크리에이터 지원 공간 운영</td>\n",
       "      <td>생활문화</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>어버이날 맑다가 흐려져…남부지방 옅은 황사</td>\n",
       "      <td>생활문화</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>내년부터 국가RD 평가 때 논문건수는 반영 않는다</td>\n",
       "      <td>사회</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>김명자 신임 과총 회장 원로와 젊은 과학자 지혜 모을 것</td>\n",
       "      <td>사회</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>회색인간 작가 김동식 양심고백 등 새 소설집 2권 출간</td>\n",
       "      <td>생활문화</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              text label\n",
       "0       유튜브 내달 2일까지 크리에이터 지원 공간 운영  생활문화\n",
       "1          어버이날 맑다가 흐려져…남부지방 옅은 황사  생활문화\n",
       "2      내년부터 국가RD 평가 때 논문건수는 반영 않는다    사회\n",
       "3  김명자 신임 과총 회장 원로와 젊은 과학자 지혜 모을 것    사회\n",
       "4   회색인간 작가 김동식 양심고백 등 새 소설집 2권 출간  생활문화"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Train-set\n",
    "with open('ynat-v1.1_train.json', mode='rt', encoding='utf-8-sig') as f:\n",
    "    train_dataset = json.load(f)\n",
    "\n",
    "train_dataset_list = [{'text':data['title'], 'label':data['label']} for data in train_dataset]\n",
    "train_df = pd.DataFrame(train_dataset_list)\n",
    "train_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a4fb658f",
   "metadata": {},
   "source": [
    "**라벨 별 개수 확인**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81a057fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T02:32:09.903884Z",
     "start_time": "2023-06-06T02:32:09.873664Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>IT과학</th>\n",
       "      <td>5235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>경제</th>\n",
       "      <td>6118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>사회</th>\n",
       "      <td>5133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>생활문화</th>\n",
       "      <td>5751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>세계</th>\n",
       "      <td>8320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>스포츠</th>\n",
       "      <td>7742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>정치</th>\n",
       "      <td>7379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       text\n",
       "label      \n",
       "IT과학   5235\n",
       "경제     6118\n",
       "사회     5133\n",
       "생활문화   5751\n",
       "세계     8320\n",
       "스포츠    7742\n",
       "정치     7379"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count by label\n",
    "train_df.groupby(by=['label']).count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e94ad69d",
   "metadata": {},
   "source": [
    "**라벨 인코딩**\n",
    "- 학습 시 Loss 계산을 하기위해 숫자 형태로 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc2712de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T02:32:10.332687Z",
     "start_time": "2023-06-06T02:32:09.905386Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>encoded_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>유튜브 내달 2일까지 크리에이터 지원 공간 운영</td>\n",
       "      <td>생활문화</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>어버이날 맑다가 흐려져…남부지방 옅은 황사</td>\n",
       "      <td>생활문화</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>내년부터 국가RD 평가 때 논문건수는 반영 않는다</td>\n",
       "      <td>사회</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>김명자 신임 과총 회장 원로와 젊은 과학자 지혜 모을 것</td>\n",
       "      <td>사회</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>회색인간 작가 김동식 양심고백 등 새 소설집 2권 출간</td>\n",
       "      <td>생활문화</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              text label  encoded_label\n",
       "0       유튜브 내달 2일까지 크리에이터 지원 공간 운영  생활문화              3\n",
       "1          어버이날 맑다가 흐려져…남부지방 옅은 황사  생활문화              3\n",
       "2      내년부터 국가RD 평가 때 논문건수는 반영 않는다    사회              2\n",
       "3  김명자 신임 과총 회장 원로와 젊은 과학자 지혜 모을 것    사회              2\n",
       "4   회색인간 작가 김동식 양심고백 등 새 소설집 2권 출간  생활문화              3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label Encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(train_df['label'])\n",
    "num_labels = len(label_encoder.classes_)\n",
    "\n",
    "train_df['encoded_label'] = np.asarray(label_encoder.transform(train_df['label']), dtype=np.int32)\n",
    "train_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "43b4a50c",
   "metadata": {},
   "source": [
    "**모델 검증을 위해 validation set을 training set의 20% 비율로 분리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bd3302c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T02:32:10.348214Z",
     "start_time": "2023-06-06T02:32:10.333687Z"
    }
   },
   "outputs": [],
   "source": [
    "train_texts = train_df[\"text\"].to_list() # Features (not-tokenized yet)\n",
    "train_labels = train_df[\"encoded_label\"].to_list() # Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "402926b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T02:32:10.409400Z",
     "start_time": "2023-06-06T02:32:10.349214Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split Train and Validation data\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "287c0ac1",
   "metadata": {},
   "source": [
    "# Tokenizing the text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bea7ec05",
   "metadata": {},
   "source": [
    "본격적으로 Tokenizing 및 pretrained 모델 사용을 위해 🤗HuggingFace의 Transformers 라이브러리를 활용한다. <br>\n",
    "Transformers를 통해 저장된 모델은 기본적으로 pretrained model, tokenizer, vocab, config 파일 등을 포함하고 있으며, **from_pretrained()** 메소드를 통해 로드할 수 있다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fbc14e19",
   "metadata": {},
   "source": [
    "KLUE-BERT Model Path\n",
    "\n",
    "- **K**orean **L**anguage **U**nderstanding **E**valuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1dbf0059",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T02:32:10.425407Z",
     "start_time": "2023-06-06T02:32:10.410400Z"
    }
   },
   "outputs": [],
   "source": [
    "HUGGINGFACE_MODEL_PATH = \"klue/bert-base\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f21fb1b5",
   "metadata": {},
   "source": [
    "여기서 이용할 KLUE-BERT모델 또한 HuggingFace Model Hub에 배포되어 있으며 해당 모델 주소를 추후 **from_pretrained()**에 인자로 넣어주어 모델을 다운로드 및 로드할 수 있음"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c2074a24",
   "metadata": {},
   "source": [
    "**Tokenizer 로드 및 Tokenizing**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c700f6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T02:32:12.244286Z",
     "start_time": "2023-06-06T02:32:10.426409Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast\n",
    "\n",
    "# Load Tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained(HUGGINGFACE_MODEL_PATH)\n",
    "\n",
    "# Tokenizing\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f10a41cd",
   "metadata": {},
   "source": [
    "**참고** <br>\n",
    "- Tokenizer는 BertTokenizer(), BertTokenizerFast() 무엇을 사용하던 상관없지만, BertTokenizerFast()가 BertTokenizer() 대비 1.2 ~ 1.5배 tokenizing 속도가 빠르다. (단, BertTokenizerFast()는 성능에 영향을 줄 수 있으니 유의하자)\n",
    "<br><br>\n",
    "\n",
    "- truncation혹은 padding 옵션을 주어 input sequence의 길이를 맞춰줄 수 있으며, 여러가지 옵션으로 세세한 튜닝도 가능하다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0f3df032",
   "metadata": {},
   "source": [
    "# Creating a Dataset object for Tensorflow\n",
    "fine-tuning을 진행하기 전에 먼저 tokenized 된 데이터 셋을 Tensorflow의 Dataset object로 변환을 위해 from_tensor_slices()메서드를 수행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a77555ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T02:32:18.928098Z",
     "start_time": "2023-06-06T02:32:12.245286Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# trainset-set\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings),\n",
    "    train_labels\n",
    "))\n",
    "\n",
    "# validation-set\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(val_encodings),\n",
    "    val_labels\n",
    "))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fd9dcab3",
   "metadata": {},
   "source": [
    "# Fine-tuning BERT\n",
    "Fine-tuning을 위해 tensorflow를 이용"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1fd0d202",
   "metadata": {},
   "source": [
    "**Load Pretrained Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7ae8697",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T02:32:18.943604Z",
     "start_time": "2023-06-06T02:32:18.930100Z"
    }
   },
   "outputs": [],
   "source": [
    "#tensorflow 버전이 안맞으면 import가 안될 수 있음\n",
    "#!pip install --user tensorflow==2.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bba337f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T02:32:18.959255Z",
     "start_time": "2023-06-06T02:32:18.943604Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f4f168d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T02:32:21.386208Z",
     "start_time": "2023-06-06T02:32:18.960258Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForSequenceClassification: ['bert.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFBertForSequenceClassification\n",
    "\n",
    "num_labels = len(label_encoder.classes_) # .class_ 메소드로 라벨 개수를 얻음\n",
    "model = TFBertForSequenceClassification.from_pretrained(HUGGINGFACE_MODEL_PATH, num_labels=num_labels, from_pt=True) # from_pt=True를 넣어서 텐서모델로 변환 및 로드가능\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "model.compile(optimizer=optimizer, loss=model.compute_loss, metrics=['accuracy'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "52f052cc",
   "metadata": {},
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ddbf83b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T02:43:11.052135Z",
     "start_time": "2023-06-06T02:32:21.387208Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:AutoGraph could not transform <function input_processing at 0x0000020CAD187280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: '<' not supported between instances of 'Literal' and 'str'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function input_processing at 0x0000020CAD187280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: '<' not supported between instances of 'Literal' and 'str'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:From C:\\Users\\ebdl\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ebdl\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:376: FutureWarning: The old compute_loss method is deprecated as it conflicts with the Keras compute_loss method added in TF 2.8. If you want the original HF compute_loss, please call hf_compute_loss() instead. From TF versions >= 2.8, or Transformers versions >= 5, calling compute_loss() will get the Keras method instead.\n",
      "  return py_builtins.overload_of(f)(*args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2284/2284 [==============================] - 223s 94ms/step - loss: 0.4313 - accuracy: 0.8561 - val_loss: 0.3483 - val_accuracy: 0.8771\n",
      "Epoch 2/5\n",
      "2284/2284 [==============================] - 212s 93ms/step - loss: 0.2785 - accuracy: 0.9044 - val_loss: 0.3800 - val_accuracy: 0.8748\n",
      "Epoch 3/5\n",
      "2284/2284 [==============================] - 214s 94ms/step - loss: 0.1905 - accuracy: 0.9343 - val_loss: 0.4564 - val_accuracy: 0.8723\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20cad22d6d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "callback_earlystop = EarlyStopping(\n",
    "    monitor=\"val_accuracy\", \n",
    "    min_delta=0.001, # the threshold that triggers the termination (acc should at least improve 0.001)\n",
    "    patience=2)\n",
    "\n",
    "model.fit(\n",
    "    train_dataset.shuffle(1000).batch(16), epochs=5, batch_size=16,\n",
    "    validation_data=val_dataset.shuffle(1000).batch(16),\n",
    "    callbacks = [callback_earlystop]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dbadf723",
   "metadata": {},
   "source": [
    "training 방법은 tf.keras에서 모델을 훈련할 때와 같음. training 사전 종료를 위해 EarlyStopping callback 함수를 적용"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "88e6a3c5",
   "metadata": {},
   "source": [
    "# Saving Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c9ebca52",
   "metadata": {},
   "source": [
    "transformers에서 제공하는 save_pretrained() 메소드를 사용하면 모델을 저장할 수 있다.<br>\n",
    "\n",
    "모델을 저장하게 되면 총 5가지의 파일이 저장 위치에 생성되며, 추후 해당 파일을 그대로 HuggingFace Model Hub로 포팅하여 손쉽게 로드할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "856431e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T02:43:11.067041Z",
     "start_time": "2023-06-06T02:43:11.053135Z"
    }
   },
   "outputs": [],
   "source": [
    "# Change id2label, label2id in model.config\n",
    "\n",
    "id2labels = model.config.id2label\n",
    "model.config.id2label = {id : label_encoder.inverse_transform([int(re.sub('LABEL_', '', label))])[0]  for id, label in id2labels.items()}\n",
    "\n",
    "label2ids = model.config.label2id\n",
    "model.config.label2id = {label_encoder.inverse_transform([int(re.sub('LABEL_', '', label))])[0] : id   for id, label in id2labels.items()}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "75fcceb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T02:14:52.292542Z",
     "start_time": "2023-06-06T02:14:52.273538Z"
    }
   },
   "source": [
    "학습된 모델은 기본적으로 모델 아키텍처, 레이어, label과 같은 모델 정보를 **config** 속성에 저장하게 된다. <br>\n",
    "이 **config**에는 ***id2label, label2id*** 라는 ***index값과 label 속성***이 매핑된 정보가 존재하는데, <br>\n",
    "우리가 위에서 LabelEncoder를 통해 label을 숫자형태로 encoding을 하여 학습하였기 때문에 해당 속성들 또한 encoding된 형태로 저장되어 있다.<br><br>\n",
    "그래서 이를 다시 **decoding함으로써 본래의 label 값을 갖도록 변환**한다.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f61a38a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T02:43:11.856354Z",
     "start_time": "2023-06-06T02:43:11.068042Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_model\\fine-tuned-klue-bert-base -- Folder already exists \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('_model\\\\fine-tuned-klue-bert-base\\\\tokenizer_config.json',\n",
       " '_model\\\\fine-tuned-klue-bert-base\\\\special_tokens_map.json',\n",
       " '_model\\\\fine-tuned-klue-bert-base\\\\vocab.txt',\n",
       " '_model\\\\fine-tuned-klue-bert-base\\\\added_tokens.json',\n",
       " '_model\\\\fine-tuned-klue-bert-base\\\\tokenizer.json')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving the model and tokenizer\n",
    "\n",
    "MODEL_NAME = 'fine-tuned-klue-bert-base'\n",
    "MODEL_SAVE_PATH = os.path.join(\"_model\", MODEL_NAME) # change this to your preferred location\n",
    "\n",
    "if os.path.exists(MODEL_SAVE_PATH):\n",
    "    print(f\"{MODEL_SAVE_PATH} -- Folder already exists \\n\")\n",
    "else:\n",
    "    os.makedirs(MODEL_SAVE_PATH, exist_ok=True)\n",
    "    print(f\"{MODEL_SAVE_PATH} -- Folder create complete \\n\")\n",
    "\n",
    "# save tokenizer, model\n",
    "model.save_pretrained(MODEL_SAVE_PATH)\n",
    "tokenizer.save_pretrained(MODEL_SAVE_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "23806db8",
   "metadata": {},
   "source": [
    "**save_pretrained() 메소드를 통해 model,tokenizer를 저장**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "71d8704f",
   "metadata": {},
   "source": [
    "경로를 Hugging space의 개인 경로로 하게 되면 온라인에서 사전에 학습한 모델을 불러올 수 있다! <br>\n",
    "(나는 로컬에 저장하였다)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f71d34bb",
   "metadata": {},
   "source": [
    "# Load the saved model and prediction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "759b2932",
   "metadata": {},
   "source": [
    "**Loading the model and tokenizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efbb626d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T02:43:12.512466Z",
     "start_time": "2023-06-06T02:43:11.857356Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at _model\\fine-tuned-klue-bert-base were not used when initializing TFBertForSequenceClassification: ['dropout_37']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at _model\\fine-tuned-klue-bert-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n",
      "C:\\Users\\ebdl\\Anaconda3\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar funcionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TextClassificationPipeline\n",
    "\n",
    "# Load Fine-tuning model\n",
    "loaded_tokenizer = BertTokenizerFast.from_pretrained(MODEL_SAVE_PATH)\n",
    "loaded_model = TFBertForSequenceClassification.from_pretrained(MODEL_SAVE_PATH)\n",
    "\n",
    "text_classifier = TextClassificationPipeline(\n",
    "    tokenizer=loaded_tokenizer, \n",
    "    model=loaded_model, \n",
    "    framework='tf',\n",
    "    return_all_scores=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "270f26f3",
   "metadata": {},
   "source": [
    "**Load Testset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2184a281",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T02:43:12.954830Z",
     "start_time": "2023-06-06T02:43:12.513465Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ebdl\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def clean_text(text):\n",
    "    cleaned_text = text.lower().strip() #  # 텍스트를 소문자로 변환하고 양쪽의 공백을 제거\n",
    "    # cleaned_text = re.sub(r'\\d+', '', cleaned_text) # 텍스트에서 숫자를 제거\n",
    "    cleaned_text = \"\".join(char for char in cleaned_text if char not in string.punctuation) # 문장부호를 제거\n",
    "    stop_words = set(stopwords.words('english'))  # 영어 불용어 집합을 가져옴\n",
    "    cleaned_text = \" \".join(word for word in cleaned_text.split() if word not in stop_words) # 불용어를 제거\n",
    "    return cleaned_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2259da0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T02:43:14.452919Z",
     "start_time": "2023-06-06T02:43:12.955779Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5억원 무이자 융자는 되고 7천만원 이사비는 안된다</td>\n",
       "      <td>사회</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>왜 수소충전소만 더 멀리 떨어져야 하나 한경연 규제개혁 건의</td>\n",
       "      <td>사회</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>항응고제 성분 코로나19에 효과…세포실험서 확인</td>\n",
       "      <td>IT과학</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>실거래가 가장 비싼 역세권은 신반포역…33㎡당 1억 육박</td>\n",
       "      <td>경제</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>기자회견 하는 성 소수자 단체</td>\n",
       "      <td>사회</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                text label\n",
       "0       5억원 무이자 융자는 되고 7천만원 이사비는 안된다    사회\n",
       "1  왜 수소충전소만 더 멀리 떨어져야 하나 한경연 규제개혁 건의    사회\n",
       "2         항응고제 성분 코로나19에 효과…세포실험서 확인  IT과학\n",
       "3    실거래가 가장 비싼 역세권은 신반포역…33㎡당 1억 육박    경제\n",
       "4                   기자회견 하는 성 소수자 단체    사회"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Test-set\n",
    "with open('ynat-v1.1_dev.json', mode='rt', encoding='utf-8-sig') as f:\n",
    "    test_dataset = json.load(f)\n",
    "\n",
    "test_dataset_list = [{'text':clean_text(data['title']), 'label':data['label']} for data in test_dataset]\n",
    "test_df = pd.DataFrame(test_dataset_list)\n",
    "test_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "02a6c65e",
   "metadata": {},
   "source": [
    "**Prediction using Pipelines**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1eadaf4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T03:08:48.406117Z",
     "start_time": "2023-06-06T02:43:14.453919Z"
    }
   },
   "outputs": [],
   "source": [
    "predicted_label_list = []\n",
    "predicted_score_list = []\n",
    "\n",
    "for text in test_df['text']:\n",
    "    # predict\n",
    "    preds_list = text_classifier(text)[0]\n",
    "\n",
    "    sorted_preds_list = sorted(preds_list, key=lambda x: x['score'], reverse=True)\n",
    "    predicted_label_list.append(sorted_preds_list[0]['label']) # label\n",
    "    predicted_score_list.append(sorted_preds_list[1]['score']) # score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4478dd92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T03:08:48.421627Z",
     "start_time": "2023-06-06T03:08:48.407117Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5억원 무이자 융자는 되고 7천만원 이사비는 안된다</td>\n",
       "      <td>사회</td>\n",
       "      <td>경제</td>\n",
       "      <td>0.004280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>왜 수소충전소만 더 멀리 떨어져야 하나 한경연 규제개혁 건의</td>\n",
       "      <td>사회</td>\n",
       "      <td>사회</td>\n",
       "      <td>0.038732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>항응고제 성분 코로나19에 효과…세포실험서 확인</td>\n",
       "      <td>IT과학</td>\n",
       "      <td>IT과학</td>\n",
       "      <td>0.002602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>실거래가 가장 비싼 역세권은 신반포역…33㎡당 1억 육박</td>\n",
       "      <td>경제</td>\n",
       "      <td>경제</td>\n",
       "      <td>0.003396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>기자회견 하는 성 소수자 단체</td>\n",
       "      <td>사회</td>\n",
       "      <td>사회</td>\n",
       "      <td>0.004397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                text label  pred     score\n",
       "0       5억원 무이자 융자는 되고 7천만원 이사비는 안된다    사회    경제  0.004280\n",
       "1  왜 수소충전소만 더 멀리 떨어져야 하나 한경연 규제개혁 건의    사회    사회  0.038732\n",
       "2         항응고제 성분 코로나19에 효과…세포실험서 확인  IT과학  IT과학  0.002602\n",
       "3    실거래가 가장 비싼 역세권은 신반포역…33㎡당 1억 육박    경제    경제  0.003396\n",
       "4                   기자회견 하는 성 소수자 단체    사회    사회  0.004397"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['pred'] = predicted_label_list\n",
    "test_df['score'] = predicted_score_list\n",
    "test_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "20501e2f",
   "metadata": {},
   "source": [
    "pred만 보면됨"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4dd465fa",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5167933",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T03:08:48.436636Z",
     "start_time": "2023-06-06T03:08:48.422627Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba6c4910",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T03:08:48.452142Z",
     "start_time": "2023-06-06T03:08:48.437636Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         사회\n",
       "1         사회\n",
       "2       IT과학\n",
       "3         경제\n",
       "4         사회\n",
       "        ... \n",
       "9102      경제\n",
       "9103      사회\n",
       "9104      경제\n",
       "9105      사회\n",
       "9106      사회\n",
       "Name: label, Length: 9107, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d3dd155",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T03:08:48.467151Z",
     "start_time": "2023-06-06T03:08:48.453143Z"
    }
   },
   "outputs": [],
   "source": [
    "#test_df['pred'] = test_df['pred'].apply(lambda x: x['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d31d24ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T03:08:48.482654Z",
     "start_time": "2023-06-06T03:08:48.468151Z"
    }
   },
   "outputs": [],
   "source": [
    "#test_df['pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2bc480dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T03:08:48.619316Z",
     "start_time": "2023-06-06T03:08:48.483654Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        IT과학       0.68      0.83      0.75       554\n",
      "          경제       0.83      0.81      0.82      1348\n",
      "          사회       0.88      0.82      0.85      3701\n",
      "        생활문화       0.79      0.89      0.84      1369\n",
      "          세계       0.89      0.83      0.86       835\n",
      "         스포츠       0.93      0.92      0.93       578\n",
      "          정치       0.80      0.86      0.83       722\n",
      "\n",
      "    accuracy                           0.84      9107\n",
      "   macro avg       0.83      0.85      0.84      9107\n",
      "weighted avg       0.84      0.84      0.84      9107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=test_df['label'], y_pred=test_df['pred']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "533a7d10",
   "metadata": {},
   "source": [
    "scikit-learn의 classification_report를 통해 label별 결과를 확인한다.<br>\n",
    "f1-score가 0.84로 기존 KLUE-BERT-BASE의 Topic Classification 점수인 85.49와 비슷한 오차범위 내로 성능 재현이 이루어졌다고 할 수 있을 것 같다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
