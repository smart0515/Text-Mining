{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4b5eac16",
   "metadata": {},
   "source": [
    "HuggingFace transformersì™€ Tensorflowë¥¼ í†µí•´ ì‚¬ì „í•™ìŠµëª¨ë¸ì„ Fine-tuningí•˜ëŠ” <br> ë°©ë²• ë° í•™ìŠµëœ ëª¨ë¸ì„ í†µí•´ **Multi-class text classfication** ë¬¸ì œë¥¼ í•´ê²°í•´ë³´ì"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f59d190e",
   "metadata": {},
   "source": [
    "# Load Dataset\n",
    "**Load Trainset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f808e51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T02:32:09.401588Z",
     "start_time": "2023-06-06T02:32:09.050259Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cf890ba6",
   "metadata": {},
   "source": [
    "- ë°ì´í„° ì…‹ì˜ ê²½ìš° KLUEì—ì„œ Topic-Classificationì„ ìœ„í•´ ì‚¬ìš©í•œ YNAT ë°ì´í„° ì…‹ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì˜€ë‹¤.<br>\n",
    "- YNATëŠ” ì—°í•©ë‰´ìŠ¤ì˜ 2016-202ë…„ê¹Œì§€ì˜ ë‰´ìŠ¤ headlineì„ ìˆ˜ì§‘í•œ ë°ì´í„° ì…‹ì´ë©°, ì´ 7ê°€ì§€ í´ë˜ìŠ¤(ITê³¼í•™, ê²½ì œ, ì‚¬íšŒ, ìƒí™œë¬¸í™”, ì„¸ê³„, ìŠ¤í¬ì¸ , ì •ì¹˜)ë¡œ ë¶„ë¥˜ë˜ì–´ìˆë‹¤."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "48a9dac3",
   "metadata": {},
   "source": [
    "**Dataset : https://github.com/KLUE-benchmark/KLUE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d3af21e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T02:32:09.873664Z",
     "start_time": "2023-06-06T02:32:09.402588Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ìœ íŠœë¸Œ ë‚´ë‹¬ 2ì¼ê¹Œì§€ í¬ë¦¬ì—ì´í„° ì§€ì› ê³µê°„ ìš´ì˜</td>\n",
       "      <td>ìƒí™œë¬¸í™”</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ì–´ë²„ì´ë‚  ë§‘ë‹¤ê°€ íë ¤ì ¸â€¦ë‚¨ë¶€ì§€ë°© ì˜…ì€ í™©ì‚¬</td>\n",
       "      <td>ìƒí™œë¬¸í™”</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ë‚´ë…„ë¶€í„° êµ­ê°€RD í‰ê°€ ë•Œ ë…¼ë¬¸ê±´ìˆ˜ëŠ” ë°˜ì˜ ì•ŠëŠ”ë‹¤</td>\n",
       "      <td>ì‚¬íšŒ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ê¹€ëª…ì ì‹ ì„ ê³¼ì´ íšŒì¥ ì›ë¡œì™€ ì Šì€ ê³¼í•™ì ì§€í˜œ ëª¨ì„ ê²ƒ</td>\n",
       "      <td>ì‚¬íšŒ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>íšŒìƒ‰ì¸ê°„ ì‘ê°€ ê¹€ë™ì‹ ì–‘ì‹¬ê³ ë°± ë“± ìƒˆ ì†Œì„¤ì§‘ 2ê¶Œ ì¶œê°„</td>\n",
       "      <td>ìƒí™œë¬¸í™”</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              text label\n",
       "0       ìœ íŠœë¸Œ ë‚´ë‹¬ 2ì¼ê¹Œì§€ í¬ë¦¬ì—ì´í„° ì§€ì› ê³µê°„ ìš´ì˜  ìƒí™œë¬¸í™”\n",
       "1          ì–´ë²„ì´ë‚  ë§‘ë‹¤ê°€ íë ¤ì ¸â€¦ë‚¨ë¶€ì§€ë°© ì˜…ì€ í™©ì‚¬  ìƒí™œë¬¸í™”\n",
       "2      ë‚´ë…„ë¶€í„° êµ­ê°€RD í‰ê°€ ë•Œ ë…¼ë¬¸ê±´ìˆ˜ëŠ” ë°˜ì˜ ì•ŠëŠ”ë‹¤    ì‚¬íšŒ\n",
       "3  ê¹€ëª…ì ì‹ ì„ ê³¼ì´ íšŒì¥ ì›ë¡œì™€ ì Šì€ ê³¼í•™ì ì§€í˜œ ëª¨ì„ ê²ƒ    ì‚¬íšŒ\n",
       "4   íšŒìƒ‰ì¸ê°„ ì‘ê°€ ê¹€ë™ì‹ ì–‘ì‹¬ê³ ë°± ë“± ìƒˆ ì†Œì„¤ì§‘ 2ê¶Œ ì¶œê°„  ìƒí™œë¬¸í™”"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Train-set\n",
    "with open('ynat-v1.1_train.json', mode='rt', encoding='utf-8-sig') as f:\n",
    "    train_dataset = json.load(f)\n",
    "\n",
    "train_dataset_list = [{'text':data['title'], 'label':data['label']} for data in train_dataset]\n",
    "train_df = pd.DataFrame(train_dataset_list)\n",
    "train_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a4fb658f",
   "metadata": {},
   "source": [
    "**ë¼ë²¨ ë³„ ê°œìˆ˜ í™•ì¸**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81a057fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T02:32:09.903884Z",
     "start_time": "2023-06-06T02:32:09.873664Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ITê³¼í•™</th>\n",
       "      <td>5235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ê²½ì œ</th>\n",
       "      <td>6118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ì‚¬íšŒ</th>\n",
       "      <td>5133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ìƒí™œë¬¸í™”</th>\n",
       "      <td>5751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ì„¸ê³„</th>\n",
       "      <td>8320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ìŠ¤í¬ì¸ </th>\n",
       "      <td>7742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ì •ì¹˜</th>\n",
       "      <td>7379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       text\n",
       "label      \n",
       "ITê³¼í•™   5235\n",
       "ê²½ì œ     6118\n",
       "ì‚¬íšŒ     5133\n",
       "ìƒí™œë¬¸í™”   5751\n",
       "ì„¸ê³„     8320\n",
       "ìŠ¤í¬ì¸     7742\n",
       "ì •ì¹˜     7379"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count by label\n",
    "train_df.groupby(by=['label']).count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e94ad69d",
   "metadata": {},
   "source": [
    "**ë¼ë²¨ ì¸ì½”ë”©**\n",
    "- í•™ìŠµ ì‹œ Loss ê³„ì‚°ì„ í•˜ê¸°ìœ„í•´ ìˆ«ì í˜•íƒœë¡œ ì¸ì½”ë”©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc2712de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T02:32:10.332687Z",
     "start_time": "2023-06-06T02:32:09.905386Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>encoded_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ìœ íŠœë¸Œ ë‚´ë‹¬ 2ì¼ê¹Œì§€ í¬ë¦¬ì—ì´í„° ì§€ì› ê³µê°„ ìš´ì˜</td>\n",
       "      <td>ìƒí™œë¬¸í™”</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ì–´ë²„ì´ë‚  ë§‘ë‹¤ê°€ íë ¤ì ¸â€¦ë‚¨ë¶€ì§€ë°© ì˜…ì€ í™©ì‚¬</td>\n",
       "      <td>ìƒí™œë¬¸í™”</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ë‚´ë…„ë¶€í„° êµ­ê°€RD í‰ê°€ ë•Œ ë…¼ë¬¸ê±´ìˆ˜ëŠ” ë°˜ì˜ ì•ŠëŠ”ë‹¤</td>\n",
       "      <td>ì‚¬íšŒ</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ê¹€ëª…ì ì‹ ì„ ê³¼ì´ íšŒì¥ ì›ë¡œì™€ ì Šì€ ê³¼í•™ì ì§€í˜œ ëª¨ì„ ê²ƒ</td>\n",
       "      <td>ì‚¬íšŒ</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>íšŒìƒ‰ì¸ê°„ ì‘ê°€ ê¹€ë™ì‹ ì–‘ì‹¬ê³ ë°± ë“± ìƒˆ ì†Œì„¤ì§‘ 2ê¶Œ ì¶œê°„</td>\n",
       "      <td>ìƒí™œë¬¸í™”</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              text label  encoded_label\n",
       "0       ìœ íŠœë¸Œ ë‚´ë‹¬ 2ì¼ê¹Œì§€ í¬ë¦¬ì—ì´í„° ì§€ì› ê³µê°„ ìš´ì˜  ìƒí™œë¬¸í™”              3\n",
       "1          ì–´ë²„ì´ë‚  ë§‘ë‹¤ê°€ íë ¤ì ¸â€¦ë‚¨ë¶€ì§€ë°© ì˜…ì€ í™©ì‚¬  ìƒí™œë¬¸í™”              3\n",
       "2      ë‚´ë…„ë¶€í„° êµ­ê°€RD í‰ê°€ ë•Œ ë…¼ë¬¸ê±´ìˆ˜ëŠ” ë°˜ì˜ ì•ŠëŠ”ë‹¤    ì‚¬íšŒ              2\n",
       "3  ê¹€ëª…ì ì‹ ì„ ê³¼ì´ íšŒì¥ ì›ë¡œì™€ ì Šì€ ê³¼í•™ì ì§€í˜œ ëª¨ì„ ê²ƒ    ì‚¬íšŒ              2\n",
       "4   íšŒìƒ‰ì¸ê°„ ì‘ê°€ ê¹€ë™ì‹ ì–‘ì‹¬ê³ ë°± ë“± ìƒˆ ì†Œì„¤ì§‘ 2ê¶Œ ì¶œê°„  ìƒí™œë¬¸í™”              3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label Encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(train_df['label'])\n",
    "num_labels = len(label_encoder.classes_)\n",
    "\n",
    "train_df['encoded_label'] = np.asarray(label_encoder.transform(train_df['label']), dtype=np.int32)\n",
    "train_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "43b4a50c",
   "metadata": {},
   "source": [
    "**ëª¨ë¸ ê²€ì¦ì„ ìœ„í•´ validation setì„ training setì˜ 20% ë¹„ìœ¨ë¡œ ë¶„ë¦¬**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bd3302c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T02:32:10.348214Z",
     "start_time": "2023-06-06T02:32:10.333687Z"
    }
   },
   "outputs": [],
   "source": [
    "train_texts = train_df[\"text\"].to_list() # Features (not-tokenized yet)\n",
    "train_labels = train_df[\"encoded_label\"].to_list() # Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "402926b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T02:32:10.409400Z",
     "start_time": "2023-06-06T02:32:10.349214Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split Train and Validation data\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "287c0ac1",
   "metadata": {},
   "source": [
    "# Tokenizing the text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bea7ec05",
   "metadata": {},
   "source": [
    "ë³¸ê²©ì ìœ¼ë¡œ Tokenizing ë° pretrained ëª¨ë¸ ì‚¬ìš©ì„ ìœ„í•´ ğŸ¤—HuggingFaceì˜ Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í™œìš©í•œë‹¤. <br>\n",
    "Transformersë¥¼ í†µí•´ ì €ì¥ëœ ëª¨ë¸ì€ ê¸°ë³¸ì ìœ¼ë¡œ pretrained model, tokenizer, vocab, config íŒŒì¼ ë“±ì„ í¬í•¨í•˜ê³  ìˆìœ¼ë©°, **from_pretrained()** ë©”ì†Œë“œë¥¼ í†µí•´ ë¡œë“œí•  ìˆ˜ ìˆë‹¤."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fbc14e19",
   "metadata": {},
   "source": [
    "KLUE-BERT Model Path\n",
    "\n",
    "- **K**orean **L**anguage **U**nderstanding **E**valuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1dbf0059",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T02:32:10.425407Z",
     "start_time": "2023-06-06T02:32:10.410400Z"
    }
   },
   "outputs": [],
   "source": [
    "HUGGINGFACE_MODEL_PATH = \"klue/bert-base\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f21fb1b5",
   "metadata": {},
   "source": [
    "ì—¬ê¸°ì„œ ì´ìš©í•  KLUE-BERTëª¨ë¸ ë˜í•œ HuggingFace Model Hubì— ë°°í¬ë˜ì–´ ìˆìœ¼ë©° í•´ë‹¹ ëª¨ë¸ ì£¼ì†Œë¥¼ ì¶”í›„ **from_pretrained()**ì— ì¸ìë¡œ ë„£ì–´ì£¼ì–´ ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œ ë° ë¡œë“œí•  ìˆ˜ ìˆìŒ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c2074a24",
   "metadata": {},
   "source": [
    "**Tokenizer ë¡œë“œ ë° Tokenizing**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c700f6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T02:32:12.244286Z",
     "start_time": "2023-06-06T02:32:10.426409Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast\n",
    "\n",
    "# Load Tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained(HUGGINGFACE_MODEL_PATH)\n",
    "\n",
    "# Tokenizing\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f10a41cd",
   "metadata": {},
   "source": [
    "**ì°¸ê³ ** <br>\n",
    "- TokenizerëŠ” BertTokenizer(), BertTokenizerFast() ë¬´ì—‡ì„ ì‚¬ìš©í•˜ë˜ ìƒê´€ì—†ì§€ë§Œ, BertTokenizerFast()ê°€ BertTokenizer() ëŒ€ë¹„ 1.2 ~ 1.5ë°° tokenizing ì†ë„ê°€ ë¹ ë¥´ë‹¤. (ë‹¨, BertTokenizerFast()ëŠ” ì„±ëŠ¥ì— ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆìœ¼ë‹ˆ ìœ ì˜í•˜ì)\n",
    "<br><br>\n",
    "\n",
    "- truncationí˜¹ì€ padding ì˜µì…˜ì„ ì£¼ì–´ input sequenceì˜ ê¸¸ì´ë¥¼ ë§ì¶°ì¤„ ìˆ˜ ìˆìœ¼ë©°, ì—¬ëŸ¬ê°€ì§€ ì˜µì…˜ìœ¼ë¡œ ì„¸ì„¸í•œ íŠœë‹ë„ ê°€ëŠ¥í•˜ë‹¤."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0f3df032",
   "metadata": {},
   "source": [
    "# Creating a Dataset object for Tensorflow\n",
    "fine-tuningì„ ì§„í–‰í•˜ê¸° ì „ì— ë¨¼ì € tokenized ëœ ë°ì´í„° ì…‹ì„ Tensorflowì˜ Dataset objectë¡œ ë³€í™˜ì„ ìœ„í•´ from_tensor_slices()ë©”ì„œë“œë¥¼ ìˆ˜í–‰í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a77555ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T02:32:18.928098Z",
     "start_time": "2023-06-06T02:32:12.245286Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# trainset-set\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings),\n",
    "    train_labels\n",
    "))\n",
    "\n",
    "# validation-set\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(val_encodings),\n",
    "    val_labels\n",
    "))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fd9dcab3",
   "metadata": {},
   "source": [
    "# Fine-tuning BERT\n",
    "Fine-tuningì„ ìœ„í•´ tensorflowë¥¼ ì´ìš©"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1fd0d202",
   "metadata": {},
   "source": [
    "**Load Pretrained Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7ae8697",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T02:32:18.943604Z",
     "start_time": "2023-06-06T02:32:18.930100Z"
    }
   },
   "outputs": [],
   "source": [
    "#tensorflow ë²„ì „ì´ ì•ˆë§ìœ¼ë©´ importê°€ ì•ˆë  ìˆ˜ ìˆìŒ\n",
    "#!pip install --user tensorflow==2.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bba337f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T02:32:18.959255Z",
     "start_time": "2023-06-06T02:32:18.943604Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f4f168d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T02:32:21.386208Z",
     "start_time": "2023-06-06T02:32:18.960258Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForSequenceClassification: ['bert.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFBertForSequenceClassification\n",
    "\n",
    "num_labels = len(label_encoder.classes_) # .class_ ë©”ì†Œë“œë¡œ ë¼ë²¨ ê°œìˆ˜ë¥¼ ì–»ìŒ\n",
    "model = TFBertForSequenceClassification.from_pretrained(HUGGINGFACE_MODEL_PATH, num_labels=num_labels, from_pt=True) # from_pt=Trueë¥¼ ë„£ì–´ì„œ í…ì„œëª¨ë¸ë¡œ ë³€í™˜ ë° ë¡œë“œê°€ëŠ¥\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "model.compile(optimizer=optimizer, loss=model.compute_loss, metrics=['accuracy'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "52f052cc",
   "metadata": {},
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ddbf83b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T02:43:11.052135Z",
     "start_time": "2023-06-06T02:32:21.387208Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:AutoGraph could not transform <function input_processing at 0x0000020CAD187280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: '<' not supported between instances of 'Literal' and 'str'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function input_processing at 0x0000020CAD187280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: '<' not supported between instances of 'Literal' and 'str'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:From C:\\Users\\ebdl\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ebdl\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:376: FutureWarning: The old compute_loss method is deprecated as it conflicts with the Keras compute_loss method added in TF 2.8. If you want the original HF compute_loss, please call hf_compute_loss() instead. From TF versions >= 2.8, or Transformers versions >= 5, calling compute_loss() will get the Keras method instead.\n",
      "  return py_builtins.overload_of(f)(*args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2284/2284 [==============================] - 223s 94ms/step - loss: 0.4313 - accuracy: 0.8561 - val_loss: 0.3483 - val_accuracy: 0.8771\n",
      "Epoch 2/5\n",
      "2284/2284 [==============================] - 212s 93ms/step - loss: 0.2785 - accuracy: 0.9044 - val_loss: 0.3800 - val_accuracy: 0.8748\n",
      "Epoch 3/5\n",
      "2284/2284 [==============================] - 214s 94ms/step - loss: 0.1905 - accuracy: 0.9343 - val_loss: 0.4564 - val_accuracy: 0.8723\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20cad22d6d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "callback_earlystop = EarlyStopping(\n",
    "    monitor=\"val_accuracy\", \n",
    "    min_delta=0.001, # the threshold that triggers the termination (acc should at least improve 0.001)\n",
    "    patience=2)\n",
    "\n",
    "model.fit(\n",
    "    train_dataset.shuffle(1000).batch(16), epochs=5, batch_size=16,\n",
    "    validation_data=val_dataset.shuffle(1000).batch(16),\n",
    "    callbacks = [callback_earlystop]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dbadf723",
   "metadata": {},
   "source": [
    "training ë°©ë²•ì€ tf.kerasì—ì„œ ëª¨ë¸ì„ í›ˆë ¨í•  ë•Œì™€ ê°™ìŒ. training ì‚¬ì „ ì¢…ë£Œë¥¼ ìœ„í•´ EarlyStopping callback í•¨ìˆ˜ë¥¼ ì ìš©"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "88e6a3c5",
   "metadata": {},
   "source": [
    "# Saving Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c9ebca52",
   "metadata": {},
   "source": [
    "transformersì—ì„œ ì œê³µí•˜ëŠ” save_pretrained() ë©”ì†Œë“œë¥¼ ì‚¬ìš©í•˜ë©´ ëª¨ë¸ì„ ì €ì¥í•  ìˆ˜ ìˆë‹¤.<br>\n",
    "\n",
    "ëª¨ë¸ì„ ì €ì¥í•˜ê²Œ ë˜ë©´ ì´ 5ê°€ì§€ì˜ íŒŒì¼ì´ ì €ì¥ ìœ„ì¹˜ì— ìƒì„±ë˜ë©°, ì¶”í›„ í•´ë‹¹ íŒŒì¼ì„ ê·¸ëŒ€ë¡œ HuggingFace Model Hubë¡œ í¬íŒ…í•˜ì—¬ ì†ì‰½ê²Œ ë¡œë“œí•  ìˆ˜ ìˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "856431e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T02:43:11.067041Z",
     "start_time": "2023-06-06T02:43:11.053135Z"
    }
   },
   "outputs": [],
   "source": [
    "# Change id2label, label2id in model.config\n",
    "\n",
    "id2labels = model.config.id2label\n",
    "model.config.id2label = {id : label_encoder.inverse_transform([int(re.sub('LABEL_', '', label))])[0]  for id, label in id2labels.items()}\n",
    "\n",
    "label2ids = model.config.label2id\n",
    "model.config.label2id = {label_encoder.inverse_transform([int(re.sub('LABEL_', '', label))])[0] : id   for id, label in id2labels.items()}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "75fcceb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T02:14:52.292542Z",
     "start_time": "2023-06-06T02:14:52.273538Z"
    }
   },
   "source": [
    "í•™ìŠµëœ ëª¨ë¸ì€ ê¸°ë³¸ì ìœ¼ë¡œ ëª¨ë¸ ì•„í‚¤í…ì²˜, ë ˆì´ì–´, labelê³¼ ê°™ì€ ëª¨ë¸ ì •ë³´ë¥¼ **config** ì†ì„±ì— ì €ì¥í•˜ê²Œ ëœë‹¤. <br>\n",
    "ì´ **config**ì—ëŠ” ***id2label, label2id*** ë¼ëŠ” ***indexê°’ê³¼ label ì†ì„±***ì´ ë§¤í•‘ëœ ì •ë³´ê°€ ì¡´ì¬í•˜ëŠ”ë°, <br>\n",
    "ìš°ë¦¬ê°€ ìœ„ì—ì„œ LabelEncoderë¥¼ í†µí•´ labelì„ ìˆ«ìí˜•íƒœë¡œ encodingì„ í•˜ì—¬ í•™ìŠµí•˜ì˜€ê¸° ë•Œë¬¸ì— í•´ë‹¹ ì†ì„±ë“¤ ë˜í•œ encodingëœ í˜•íƒœë¡œ ì €ì¥ë˜ì–´ ìˆë‹¤.<br><br>\n",
    "ê·¸ë˜ì„œ ì´ë¥¼ ë‹¤ì‹œ **decodingí•¨ìœ¼ë¡œì¨ ë³¸ë˜ì˜ label ê°’ì„ ê°–ë„ë¡ ë³€í™˜**í•œë‹¤.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f61a38a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T02:43:11.856354Z",
     "start_time": "2023-06-06T02:43:11.068042Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_model\\fine-tuned-klue-bert-base -- Folder already exists \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('_model\\\\fine-tuned-klue-bert-base\\\\tokenizer_config.json',\n",
       " '_model\\\\fine-tuned-klue-bert-base\\\\special_tokens_map.json',\n",
       " '_model\\\\fine-tuned-klue-bert-base\\\\vocab.txt',\n",
       " '_model\\\\fine-tuned-klue-bert-base\\\\added_tokens.json',\n",
       " '_model\\\\fine-tuned-klue-bert-base\\\\tokenizer.json')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving the model and tokenizer\n",
    "\n",
    "MODEL_NAME = 'fine-tuned-klue-bert-base'\n",
    "MODEL_SAVE_PATH = os.path.join(\"_model\", MODEL_NAME) # change this to your preferred location\n",
    "\n",
    "if os.path.exists(MODEL_SAVE_PATH):\n",
    "    print(f\"{MODEL_SAVE_PATH} -- Folder already exists \\n\")\n",
    "else:\n",
    "    os.makedirs(MODEL_SAVE_PATH, exist_ok=True)\n",
    "    print(f\"{MODEL_SAVE_PATH} -- Folder create complete \\n\")\n",
    "\n",
    "# save tokenizer, model\n",
    "model.save_pretrained(MODEL_SAVE_PATH)\n",
    "tokenizer.save_pretrained(MODEL_SAVE_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "23806db8",
   "metadata": {},
   "source": [
    "**save_pretrained() ë©”ì†Œë“œë¥¼ í†µí•´ model,tokenizerë¥¼ ì €ì¥**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "71d8704f",
   "metadata": {},
   "source": [
    "ê²½ë¡œë¥¼ Hugging spaceì˜ ê°œì¸ ê²½ë¡œë¡œ í•˜ê²Œ ë˜ë©´ ì˜¨ë¼ì¸ì—ì„œ ì‚¬ì „ì— í•™ìŠµí•œ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆë‹¤! <br>\n",
    "(ë‚˜ëŠ” ë¡œì»¬ì— ì €ì¥í•˜ì˜€ë‹¤)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f71d34bb",
   "metadata": {},
   "source": [
    "# Load the saved model and prediction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "759b2932",
   "metadata": {},
   "source": [
    "**Loading the model and tokenizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efbb626d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T02:43:12.512466Z",
     "start_time": "2023-06-06T02:43:11.857356Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at _model\\fine-tuned-klue-bert-base were not used when initializing TFBertForSequenceClassification: ['dropout_37']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at _model\\fine-tuned-klue-bert-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n",
      "C:\\Users\\ebdl\\Anaconda3\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar funcionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TextClassificationPipeline\n",
    "\n",
    "# Load Fine-tuning model\n",
    "loaded_tokenizer = BertTokenizerFast.from_pretrained(MODEL_SAVE_PATH)\n",
    "loaded_model = TFBertForSequenceClassification.from_pretrained(MODEL_SAVE_PATH)\n",
    "\n",
    "text_classifier = TextClassificationPipeline(\n",
    "    tokenizer=loaded_tokenizer, \n",
    "    model=loaded_model, \n",
    "    framework='tf',\n",
    "    return_all_scores=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "270f26f3",
   "metadata": {},
   "source": [
    "**Load Testset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2184a281",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T02:43:12.954830Z",
     "start_time": "2023-06-06T02:43:12.513465Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ebdl\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def clean_text(text):\n",
    "    cleaned_text = text.lower().strip() #  # í…ìŠ¤íŠ¸ë¥¼ ì†Œë¬¸ìë¡œ ë³€í™˜í•˜ê³  ì–‘ìª½ì˜ ê³µë°±ì„ ì œê±°\n",
    "    # cleaned_text = re.sub(r'\\d+', '', cleaned_text) # í…ìŠ¤íŠ¸ì—ì„œ ìˆ«ìë¥¼ ì œê±°\n",
    "    cleaned_text = \"\".join(char for char in cleaned_text if char not in string.punctuation) # ë¬¸ì¥ë¶€í˜¸ë¥¼ ì œê±°\n",
    "    stop_words = set(stopwords.words('english'))  # ì˜ì–´ ë¶ˆìš©ì–´ ì§‘í•©ì„ ê°€ì ¸ì˜´\n",
    "    cleaned_text = \" \".join(word for word in cleaned_text.split() if word not in stop_words) # ë¶ˆìš©ì–´ë¥¼ ì œê±°\n",
    "    return cleaned_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2259da0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T02:43:14.452919Z",
     "start_time": "2023-06-06T02:43:12.955779Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5ì–µì› ë¬´ì´ì ìœµìëŠ” ë˜ê³  7ì²œë§Œì› ì´ì‚¬ë¹„ëŠ” ì•ˆëœë‹¤</td>\n",
       "      <td>ì‚¬íšŒ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ì™œ ìˆ˜ì†Œì¶©ì „ì†Œë§Œ ë” ë©€ë¦¬ ë–¨ì–´ì ¸ì•¼ í•˜ë‚˜ í•œê²½ì—° ê·œì œê°œí˜ ê±´ì˜</td>\n",
       "      <td>ì‚¬íšŒ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>í•­ì‘ê³ ì œ ì„±ë¶„ ì½”ë¡œë‚˜19ì— íš¨ê³¼â€¦ì„¸í¬ì‹¤í—˜ì„œ í™•ì¸</td>\n",
       "      <td>ITê³¼í•™</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ì‹¤ê±°ë˜ê°€ ê°€ì¥ ë¹„ì‹¼ ì—­ì„¸ê¶Œì€ ì‹ ë°˜í¬ì—­â€¦33ã¡ë‹¹ 1ì–µ ìœ¡ë°•</td>\n",
       "      <td>ê²½ì œ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ê¸°ìíšŒê²¬ í•˜ëŠ” ì„± ì†Œìˆ˜ì ë‹¨ì²´</td>\n",
       "      <td>ì‚¬íšŒ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                text label\n",
       "0       5ì–µì› ë¬´ì´ì ìœµìëŠ” ë˜ê³  7ì²œë§Œì› ì´ì‚¬ë¹„ëŠ” ì•ˆëœë‹¤    ì‚¬íšŒ\n",
       "1  ì™œ ìˆ˜ì†Œì¶©ì „ì†Œë§Œ ë” ë©€ë¦¬ ë–¨ì–´ì ¸ì•¼ í•˜ë‚˜ í•œê²½ì—° ê·œì œê°œí˜ ê±´ì˜    ì‚¬íšŒ\n",
       "2         í•­ì‘ê³ ì œ ì„±ë¶„ ì½”ë¡œë‚˜19ì— íš¨ê³¼â€¦ì„¸í¬ì‹¤í—˜ì„œ í™•ì¸  ITê³¼í•™\n",
       "3    ì‹¤ê±°ë˜ê°€ ê°€ì¥ ë¹„ì‹¼ ì—­ì„¸ê¶Œì€ ì‹ ë°˜í¬ì—­â€¦33ã¡ë‹¹ 1ì–µ ìœ¡ë°•    ê²½ì œ\n",
       "4                   ê¸°ìíšŒê²¬ í•˜ëŠ” ì„± ì†Œìˆ˜ì ë‹¨ì²´    ì‚¬íšŒ"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Test-set\n",
    "with open('ynat-v1.1_dev.json', mode='rt', encoding='utf-8-sig') as f:\n",
    "    test_dataset = json.load(f)\n",
    "\n",
    "test_dataset_list = [{'text':clean_text(data['title']), 'label':data['label']} for data in test_dataset]\n",
    "test_df = pd.DataFrame(test_dataset_list)\n",
    "test_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "02a6c65e",
   "metadata": {},
   "source": [
    "**Prediction using Pipelines**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1eadaf4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T03:08:48.406117Z",
     "start_time": "2023-06-06T02:43:14.453919Z"
    }
   },
   "outputs": [],
   "source": [
    "predicted_label_list = []\n",
    "predicted_score_list = []\n",
    "\n",
    "for text in test_df['text']:\n",
    "    # predict\n",
    "    preds_list = text_classifier(text)[0]\n",
    "\n",
    "    sorted_preds_list = sorted(preds_list, key=lambda x: x['score'], reverse=True)\n",
    "    predicted_label_list.append(sorted_preds_list[0]['label']) # label\n",
    "    predicted_score_list.append(sorted_preds_list[1]['score']) # score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4478dd92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T03:08:48.421627Z",
     "start_time": "2023-06-06T03:08:48.407117Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5ì–µì› ë¬´ì´ì ìœµìëŠ” ë˜ê³  7ì²œë§Œì› ì´ì‚¬ë¹„ëŠ” ì•ˆëœë‹¤</td>\n",
       "      <td>ì‚¬íšŒ</td>\n",
       "      <td>ê²½ì œ</td>\n",
       "      <td>0.004280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ì™œ ìˆ˜ì†Œì¶©ì „ì†Œë§Œ ë” ë©€ë¦¬ ë–¨ì–´ì ¸ì•¼ í•˜ë‚˜ í•œê²½ì—° ê·œì œê°œí˜ ê±´ì˜</td>\n",
       "      <td>ì‚¬íšŒ</td>\n",
       "      <td>ì‚¬íšŒ</td>\n",
       "      <td>0.038732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>í•­ì‘ê³ ì œ ì„±ë¶„ ì½”ë¡œë‚˜19ì— íš¨ê³¼â€¦ì„¸í¬ì‹¤í—˜ì„œ í™•ì¸</td>\n",
       "      <td>ITê³¼í•™</td>\n",
       "      <td>ITê³¼í•™</td>\n",
       "      <td>0.002602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ì‹¤ê±°ë˜ê°€ ê°€ì¥ ë¹„ì‹¼ ì—­ì„¸ê¶Œì€ ì‹ ë°˜í¬ì—­â€¦33ã¡ë‹¹ 1ì–µ ìœ¡ë°•</td>\n",
       "      <td>ê²½ì œ</td>\n",
       "      <td>ê²½ì œ</td>\n",
       "      <td>0.003396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ê¸°ìíšŒê²¬ í•˜ëŠ” ì„± ì†Œìˆ˜ì ë‹¨ì²´</td>\n",
       "      <td>ì‚¬íšŒ</td>\n",
       "      <td>ì‚¬íšŒ</td>\n",
       "      <td>0.004397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                text label  pred     score\n",
       "0       5ì–µì› ë¬´ì´ì ìœµìëŠ” ë˜ê³  7ì²œë§Œì› ì´ì‚¬ë¹„ëŠ” ì•ˆëœë‹¤    ì‚¬íšŒ    ê²½ì œ  0.004280\n",
       "1  ì™œ ìˆ˜ì†Œì¶©ì „ì†Œë§Œ ë” ë©€ë¦¬ ë–¨ì–´ì ¸ì•¼ í•˜ë‚˜ í•œê²½ì—° ê·œì œê°œí˜ ê±´ì˜    ì‚¬íšŒ    ì‚¬íšŒ  0.038732\n",
       "2         í•­ì‘ê³ ì œ ì„±ë¶„ ì½”ë¡œë‚˜19ì— íš¨ê³¼â€¦ì„¸í¬ì‹¤í—˜ì„œ í™•ì¸  ITê³¼í•™  ITê³¼í•™  0.002602\n",
       "3    ì‹¤ê±°ë˜ê°€ ê°€ì¥ ë¹„ì‹¼ ì—­ì„¸ê¶Œì€ ì‹ ë°˜í¬ì—­â€¦33ã¡ë‹¹ 1ì–µ ìœ¡ë°•    ê²½ì œ    ê²½ì œ  0.003396\n",
       "4                   ê¸°ìíšŒê²¬ í•˜ëŠ” ì„± ì†Œìˆ˜ì ë‹¨ì²´    ì‚¬íšŒ    ì‚¬íšŒ  0.004397"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['pred'] = predicted_label_list\n",
    "test_df['score'] = predicted_score_list\n",
    "test_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "20501e2f",
   "metadata": {},
   "source": [
    "predë§Œ ë³´ë©´ë¨"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4dd465fa",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5167933",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T03:08:48.436636Z",
     "start_time": "2023-06-06T03:08:48.422627Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba6c4910",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T03:08:48.452142Z",
     "start_time": "2023-06-06T03:08:48.437636Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         ì‚¬íšŒ\n",
       "1         ì‚¬íšŒ\n",
       "2       ITê³¼í•™\n",
       "3         ê²½ì œ\n",
       "4         ì‚¬íšŒ\n",
       "        ... \n",
       "9102      ê²½ì œ\n",
       "9103      ì‚¬íšŒ\n",
       "9104      ê²½ì œ\n",
       "9105      ì‚¬íšŒ\n",
       "9106      ì‚¬íšŒ\n",
       "Name: label, Length: 9107, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d3dd155",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T03:08:48.467151Z",
     "start_time": "2023-06-06T03:08:48.453143Z"
    }
   },
   "outputs": [],
   "source": [
    "#test_df['pred'] = test_df['pred'].apply(lambda x: x['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d31d24ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T03:08:48.482654Z",
     "start_time": "2023-06-06T03:08:48.468151Z"
    }
   },
   "outputs": [],
   "source": [
    "#test_df['pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2bc480dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T03:08:48.619316Z",
     "start_time": "2023-06-06T03:08:48.483654Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ITê³¼í•™       0.68      0.83      0.75       554\n",
      "          ê²½ì œ       0.83      0.81      0.82      1348\n",
      "          ì‚¬íšŒ       0.88      0.82      0.85      3701\n",
      "        ìƒí™œë¬¸í™”       0.79      0.89      0.84      1369\n",
      "          ì„¸ê³„       0.89      0.83      0.86       835\n",
      "         ìŠ¤í¬ì¸        0.93      0.92      0.93       578\n",
      "          ì •ì¹˜       0.80      0.86      0.83       722\n",
      "\n",
      "    accuracy                           0.84      9107\n",
      "   macro avg       0.83      0.85      0.84      9107\n",
      "weighted avg       0.84      0.84      0.84      9107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=test_df['label'], y_pred=test_df['pred']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "533a7d10",
   "metadata": {},
   "source": [
    "scikit-learnì˜ classification_reportë¥¼ í†µí•´ labelë³„ ê²°ê³¼ë¥¼ í™•ì¸í•œë‹¤.<br>\n",
    "f1-scoreê°€ 0.84ë¡œ ê¸°ì¡´ KLUE-BERT-BASEì˜ Topic Classification ì ìˆ˜ì¸ 85.49ì™€ ë¹„ìŠ·í•œ ì˜¤ì°¨ë²”ìœ„ ë‚´ë¡œ ì„±ëŠ¥ ì¬í˜„ì´ ì´ë£¨ì–´ì¡Œë‹¤ê³  í•  ìˆ˜ ìˆì„ ê²ƒ ê°™ë‹¤."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
